# MutilModel Retrieval On Dataflow

## ğŸ“– Chapter 1 : Run Baseline

### 1.0 Complete the setup of the Python environment

``` 
git clone https://github.com/harsha-simhadri/big-ann-benchmarks.git
cd big-ann-benchmarks
conda create -n bann python=3.10
pip install -r requirements_py3.10.txt
```

PS:è¿™é‡Œå¯èƒ½ä¼šæŠ¥matplotlibçš„é”™ï¼Œtxté‡Œé¢åˆ é™¤matplotlibçš„ç‰ˆæœ¬å·å³å¯

---

### 1.1 Build the docker container baseline

æ­¤ä¸¾ç›®çš„ä¸ºäº†æ„å»ºåŸºäº **[Developed algorithms name]** çš„é•œåƒä»¥ä¾›æµ‹è¯•

- The baselines were run on an Azure Standard D8lds v5 (8 vcpus, 16 GiB memory) machine.
- è™½ç„¶ Docker æ”¯æŒåˆ†é… vCPUs å¤§äºç‰©ç†æ ¸æ•°ï¼Œä½†æœ€å¥½è¿˜æ˜¯åœ¨8æ ¸åŠä»¥ä¸Šçš„ CPU ä¸Šè¿è¡Œ

``` python
python install.py --neurips23track streaming --algorithm diskann
python install.py --neurips23track streaming --algorithm pyanns
python install.py --neurips23track streaming --algorithm [Developed algorithms name]
```

---

### 1.2 Test the benchmark using the algorithm's definition file

åœ¨data/random10000ä¸‹å­˜æœ‰data_10000_768ï¼Œqueries_1000_768_gtï¼Œqueries_1000_768_queryæ–‡ä»¶

#### 1.2.1 Streaming scenario testing based on ANN

ä¸ºäº†æµ‹è¯•ANNåœ¨æµæ•°æ®ä¸Šçš„æ€§èƒ½ï¼Œæ›´æ”¹**queries_1000_768_gt**ä¸º**queries_1000_768**ï¼Œè¿è¡Œï¼š

```
python run.py --neurips23track streaming --algorithm diskann --dataset random-xs --runbook_path neurips23/runbooks/simple_runbook.yaml
python run.py --neurips23track streaming --algorithm pyanns --dataset random-xs --runbook_path neurips23/runbooks/simple_runbook.yaml
```

åœ¨results/neurips23/streamingä¸‹å¾—åˆ°ç›¸åº”çš„hdf5æ–‡ä»¶ï¼Œè¯¥æ–‡ä»¶å­˜å‚¨äº†æ¯æ¬¡searchçš„ç»“æœ[ANNç®—æ³•æœç´¢åˆ°çš„'æ¯ä¸ªqueryçš„'Kä¸ªæœ€è¿‘é‚»çš„'åºåˆ—å·<===>(n, querynum, k)]

---

#### 1.2.2 Rename

å°†**queries_1000_768**æ”¹å›**queries_1000_768_gt**

---

#### 1.2.3 Streaming scenario testing based on KNN

ä¸ºäº†å¾—åˆ°groundtruthä»¥ä¾›æµ‹è¯•recallï¼Œæ›´æ”¹**queries_1000_768_query**ä¸º**queries_1000_768**

é¦–å…ˆè¦å®‰è£…ä¸€ä¸ªä¸“ç”¨äºstreamingçš„è¯„ä¼°å·¥å…·

``` 
git clone https://github.com/microsoft/DiskANN.git
cd DiskANN
mkdir build
cd build
cmake ..
make
```

å¼€å§‹è¿›è¡Œè®¡ç®—GroundTruth

``` python
python benchmark/streaming/compute_gt.py --dataset random-xs --runbook neurips23/runbooks/simple_runbook.yaml --gt_cmdline_tool DiskANN/build/apps/utils/compute_groundtruth
```

---

### 1.3 è®¡ç®— Recall

```
sudo chmod 777 -R results/
python data_export.py --out res.csv
```

---

## ğŸ“– Chapter 2 : More Detail of Baseline

### 2.1 About Docker

åˆ©ç”¨neurips23/streaming/[Developed algorithms name]ä¸‹çš„Dockerfileè¿›è¡Œå®‰è£…(big-annçš„æºç å¯èƒ½å·²ç»åœ¨dockerä¸­)
- å®‰è£…ä¾èµ–
- ä¸‹è½½ç®—æ³•çš„æºä»£ç 
- è®¾ç½®å·¥ä½œç›®å½•
- å®‰è£… Python ç¯å¢ƒå’Œæ„å»ºå·¥å…·
- æ„å»ºå¹¶å®‰è£…ç®—æ³•çš„ Python åŒ…

---

### 2.2 About Runbook

Runbookä½äºneurips23/runbooks/ä¸‹ï¼Œæœ‰å¤šä¸ªrunbookå¯ä¾›é€‰æ‹©ï¼Œæ¯ä¸ªrunbookä¸­æœ‰è¡¨æ˜å¯ç”¨çš„æ•°æ®é›†

ä»¥simple_runbook.yamlä¸ºä¾‹
``` python
random-xs:                      # å¯ç”¨çš„æ•°æ®é›†
  max_pts: 10000                # æœ€å¤§ç‚¹æ•°(ä¸Šé™)
  1:                            # åŠ¨ä½œç¼–å·
    operation: "insert"         # åŠ¨ä½œåç§°
    start: 0                    # å¼€å§‹ç‚¹ç¼–å·
    end: 10000                  # ç»“æŸç‚¹ç¼–å·
  2:
    operation: "search"
  3:
    operation: "delete"
    start: 0
    end: 5000
  4:
    operation: "search"
  5:
    operation: "insert"
    start: 0
    end: 5000
  6:
    operation: "search"
  gt_url: "https://comp21storage.z5.web.core.windows.net/comp23/str_gt/random10000/10000/simple_runbook.yaml" # ç”¨äºä¸‹è½½çœŸå€¼
...
```

---

### 2.3 About Run.py 

#### 2.3.1 é¦–å…ˆæ˜¯é€šè¿‡run_dockerè¿›è¡Œå®¹å™¨å®ä¾‹åŒ–

``` python
def run_docker(definition, dataset, count, runs, timeout, rebuild,
               cpu_limit, mem_limit=None,
               t3=None, power_capture=None,
               upload_index=False, download_index=False,
               blob_prefix="", sas_string="", private_query=False,
               neurips23track='none', runbook_path='neurips23/streaming/simple_runbook.yaml')
```

- dataset: random-xs
- count: 10
- runs: 5
- timeout: 43200
- rebuild: False
- cpu_limit: 0-11
- mem_limit: 26611702528
- t3: False
- power_capture: 
- upload_index: False
- download_index: False
- blob_prefix: None
- sas_string: None
- private_query: False
- neurips23track: streaming
- runbook_path: neurips23/runbooks/simple_runbook.yaml

å…·ä½“è¿è¡Œæ—¶çš„ä¼ å‚ä»¥åŠå…¶ä»–è®¾ç½®éƒ½åœ¨ä»¥ä¸‹ä»£ç è®¾å®šï¼š

``` python
container = client.containers.run(
    definition.docker_tag,
    cmd,
    volumes={
        os.path.abspath('benchmark'):
            {'bind': '/home/app/benchmark', 'mode': 'ro'},
        os.path.abspath('data'):
            {'bind': '/home/app/data', 'mode': 'rw'},
        os.path.abspath('results'):
            {'bind': '/home/app/results', 'mode': 'rw'},
        os.path.abspath('neurips23'):
            {'bind': '/home/app/neurips23', 'mode': 'ro'},
    },
    cpuset_cpus=cpu_limit,
    mem_limit=mem_limit,
    detach=True)
```

cmdçš„å†…å®¹ï¼Œå…·ä½“ä¼ å…¥çš„ç¨‹åºæ˜¯run_algorithm.pyè¿™ä¸ªç¨‹åº
- ['--dataset', 'random-xs', '--algorithm', 'pyanns', '--module', 'neurips23.streaming.pyanns.pyanns', '--constructor', 'Pyanns', '--runs', '5', '--count', '10', '--neurips23track', 'streaming', '--runbook_path', 'neurips23/runbooks/simple_runbook.yaml', '["euclidean", {"R": 32, "L": 50, "insert_threads": 16, "consolidate_threads": 16}]', '[{"Ls": 50, "T": 8}]']


#### 2.3.2 å…¶æ¬¡æ˜¯æ‰§è¡Œrun_algorithm.pyç¨‹åº

å…·ä½“è·å–ç®—æ³•çš„config.yamlçš„ä»£ç åœ¨benchmark/main.pyä¸‹ï¼š

``` python
definitions = get_all_definitions(
            neurips23.common.track_path(args.neurips23track), 
            dimension, args.dataset, distance, args.count)
```

éšåä¼šæ ¹æ® **ç®—æ³•-æ•°æ®-Runbook** è¿›è¡Œstreamingæµ‹è¯•

---

### 2.4 ç›¸å…³æŒ‡æ ‡è¯´æ˜

ä¸è®ºæ˜¯run.pyè¿˜æ˜¯benchmark/streaming/compute_gt.pyï¼Œéƒ½æ²¡æœ‰è¿›è¡ŒRecallçš„è®¡ç®—

run.pyç»“æŸåï¼Œå¾—åˆ°çš„hdf5æ–‡ä»¶ï¼š

```
algo: pyanns
build_time: 0.0064868927001953125               
count: 10
dataset: random-xs
distance: euclidean
index_size: 11612.0
name: pyanns(('R32_L50', {'Ls': 50, 'T': 8}))
num_searches: 3
private_queries: False
run_count: 1
search_times: []
step_0: 2
step_1: 4
step_2: 6
type: knn
Datasets and Groups:
Reading group: /
Dataset neighbors_step2:
[8101 8514 7743  523 1358 5143 5327 9704 5193 7686]
...
Dataset neighbors_step4:
[8101 8514 7743 5143 5327 9704 5193 7686 7488 6458]
...
```

benchmark/streaming/compute_gt.pyç»“æŸåï¼Œå¾—åˆ°çš„æ–‡ä»¶ï¼š

```
[[6654. 7213. 6888. ... 4614.  267. 3560.]
...
 [6654. 7213. 6888. ... 3560. 5956. 4614.]]
[[22557.51367188 22759.91210938 22793.02539062 ... 24223.93359375
  24226.04492188 24230.625     ]
...
 [22570.55273438 22774.61914062 22806.61914062 ... 24225.58984375
  24230.97851562 24235.41210938]]
```

æ˜¯ä¸¤ä¸ª(1000, 100)çš„æ•°æ®ï¼Œç¬¬ä¸€ä¸ªknnä¸‹çš„kä¸ªæœ€è¿‘é‚»çš„id,ç¬¬äºŒä¸ªæ˜¯è·ç¦»queryçš„ç›¸åº”è·ç¦»

data_export.pyæœ€ç»ˆä¼šå®Œæˆä¸€äº›æ€§èƒ½æŒ‡æ ‡çš„è®¡ç®—ï¼Œç›®å‰Streamingå¥½åƒåªæœ‰Recall


| Algorithm | Parameters                                        | Dataset                         | Count | DistComps | Build | IndexSize | Mean SSD IOs | Mean Latency | Track   | Recall/AP |
|-----------|---------------------------------------------------|---------------------------------|-------|-----------|-------|-----------|--------------|--------------|---------|-----------|
| diskann   | diskann(('R64_L50', {'Ls': 100, 'T': 16}))       | msturing-10M-clustered(delete_runbook.yaml) | 10    | 0.0       | 0.8402106761932373 | 2847936.0   | 0.0          | 0.0          | streaming | 0.8288063636363635 |


``` python
all_metrics = {
    "k-nn": {
        "description": "Recall",
        "function": lambda true_nn, run_nn, metrics, run_attrs: knn(true_nn, run_nn, run_attrs["count"], metrics).attrs['mean'],  # noqa
        "worst": float("-inf"),
        "lim": [0.0, 1.03],
    },
    "distcomps": {
        "description": "Distance computations",
        "function": lambda true_nn, run_nn,  metrics, run_attrs: dist_computations(len(true_nn[0]), run_attrs), # noqa
        "worst": float("inf")
    },
    "build": {
        "description": "Build time (s)",
        "function": lambda true_nn, run_nn, metrics, run_attrs: build_time(run_attrs), # noqa
        "worst": float("inf")
    },
    "indexsize": {
        "description": "Index size (kB)",
        "function": lambda true_nn, run_nn, metrics, run_attrs: index_size(run_attrs),  # noqa
        "worst": float("inf")
    },
    "mean_ssd_ios": {
        "description": "Average SSD I/Os per query",
        "function": lambda true_nn, run_nn, metrics, run_attrs: mean_ssd_ios(run_attrs),  
        "worst": float("inf")
    },
    "mean_latency": {
        "description": "Mean latency across queries",
        "function": lambda true_nn, run_nn, metrics, run_attrs: mean_latency(run_attrs),  
        "worst": float("inf")
    },
}
```

---

## ğŸ“– Chapter 3 : Cirr Baseline

### 3.1 Prepare Data

``` python
python create_dataset.py --dataset cirr
```

python run.py --neurips23track streaming --algorithm diskann --dataset cirr --runbook_path neurips23/runbooks/simple_runbook.yaml
python benchmark/streaming/compute_gt.py --dataset cirr --runbook neurips23/runbooks/simple_runbook.yaml --gt_cmdline_tool DiskANN/build/apps/utils/compute_groundtruth